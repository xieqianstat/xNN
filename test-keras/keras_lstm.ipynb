{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aug 11 2017\n",
    "try keras for lstm on image classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 10)\n",
      "{'_consumers': [],\n",
      " '_dtype': tf.float32,\n",
      " '_handle_dtype': 0,\n",
      " '_handle_shape': unknown_rank: true\n",
      ",\n",
      " '_keras_history': (<keras.layers.core.Dense object at 0x11c671290>, 0, 0),\n",
      " '_keras_shape': (None, 10),\n",
      " '_op': <tf.Operation 'dense_26/Softmax' type=Softmax>,\n",
      " '_shape': TensorShape([Dimension(None), Dimension(10)]),\n",
      " '_uses_learning_phase': False,\n",
      " '_value_index': 0}\n"
     ]
    }
   ],
   "source": [
    "# This returns a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.layers.core.Dense object at 0x11c7f2510>, <keras.layers.core.Activation object at 0x11c98f610>, <keras.layers.core.Dense object at 0x11c9abe90>, <keras.layers.core.Activation object at 0x11c98f090>, <keras.layers.core.Dense object at 0x11c98f7d0>, <keras.layers.core.Activation object at 0x11927b3d0>]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Stacking layers use .add()\n",
    "model.add(Dense(units=64, input_dim=784))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# compile model configure its learning process with .compile()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "\n",
    "print(model.layers)\n",
    "#pprint(vars(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "# train in batches\n",
    "BATCH_SIZE = 10000\n",
    "TRAINING_ITER = 100\n",
    "\n",
    "x_batch, y_batch = mnist.train.next_batch(BATCH_SIZE)\n",
    "# iterate on your training data in batches\n",
    "model.train_on_batch(x_batch, y_batch)\n",
    "model.fit(x_batch, y_batch, epochs=100, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8000/10000 [=======================>......] - ETA: 0s(10000, 10)\n",
      "[(10000,), (10000,)]\n",
      "[0.25282399058341981, 0.92799999713897707]\n",
      "('classification rate is', '92.80%.')\n"
     ]
    }
   ],
   "source": [
    "# Evaluate your performance in one line\n",
    "x_test, y_test = mnist.train.next_batch(BATCH_SIZE)\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=1000)\n",
    "# generate predictions on new data:\n",
    "classes = model.predict(x_test, batch_size=100)\n",
    "\n",
    "print(classes.shape)\n",
    "\n",
    "import numpy as np\n",
    "pred = np.argmax(classes, axis=1)\n",
    "trut = np.argmax(y_test, axis=1)\n",
    "\n",
    "print([pred.shape, trut.shape])\n",
    "print loss_and_metrics\n",
    "print (\"classification rate is\", \"{0:2.2f}%.\".format((pred==trut).sum()/float(pred.shape[0])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_built': True,\n",
      " '_feed_input_names': ['dense_29_input'],\n",
      " '_feed_inputs': [<tf.Tensor 'dense_29_input:0' shape=(?, 784) dtype=float32>],\n",
      " '_initial_weights': None,\n",
      " '_output_mask_cache': {'4773660048_4356911000': None},\n",
      " '_output_shape_cache': {},\n",
      " '_output_tensor_cache': {},\n",
      " '_trainable': True,\n",
      " 'container_nodes': set(['activation_5_ib-0',\n",
      "                         'activation_6_ib-0',\n",
      "                         'dense_29_ib-0',\n",
      "                         'dense_29_input_ib-0',\n",
      "                         'dense_30_ib-0']),\n",
      " 'inbound_nodes': [<keras.engine.topology.Node object at 0x11c874f10>],\n",
      " 'input_layers': [<keras.engine.topology.InputLayer object at 0x11c874890>],\n",
      " 'input_layers_node_indices': [0],\n",
      " 'input_layers_tensor_indices': [0],\n",
      " 'input_names': ['dense_29_input'],\n",
      " 'inputs': [<tf.Tensor 'dense_29_input:0' shape=(?, 784) dtype=float32>],\n",
      " 'layers': [<keras.layers.core.Dense object at 0x11c7695d0>,\n",
      "            <keras.layers.core.Activation object at 0x11c874210>,\n",
      "            <keras.layers.core.Dense object at 0x11c874a90>,\n",
      "            <keras.layers.core.Activation object at 0x11c874fd0>],\n",
      " 'loss': 'categorical_crossentropy',\n",
      " 'loss_weights': None,\n",
      " 'metrics': ['accuracy'],\n",
      " 'metrics_names': ['loss', 'acc'],\n",
      " 'metrics_tensors': [<tf.Tensor 'Mean_11:0' shape=() dtype=float32>],\n",
      " 'model': <keras.engine.training.Model object at 0x11c891ad0>,\n",
      " 'name': 'sequential_3',\n",
      " 'nodes_by_depth': {0: [<keras.engine.topology.Node object at 0x11c884c10>],\n",
      "                    1: [<keras.engine.topology.Node object at 0x11c8748d0>],\n",
      "                    2: [<keras.engine.topology.Node object at 0x11c874f90>],\n",
      "                    3: [<keras.engine.topology.Node object at 0x11c805f50>],\n",
      "                    4: [<keras.engine.topology.Node object at 0x11c5be890>]},\n",
      " 'optimizer': <keras.optimizers.SGD object at 0x11c8c0150>,\n",
      " 'outbound_nodes': [],\n",
      " 'output_layers': [<keras.layers.core.Activation object at 0x11c874fd0>],\n",
      " 'output_layers_node_indices': [0],\n",
      " 'output_layers_tensor_indices': [0],\n",
      " 'output_names': ['activation_6'],\n",
      " 'outputs': [<tf.Tensor 'activation_6/Softmax:0' shape=(?, 10) dtype=float32>],\n",
      " 'sample_weight_mode': None,\n",
      " 'sample_weights': [<tf.Tensor 'activation_6_sample_weights:0' shape=(?,) dtype=float32>],\n",
      " 'supports_masking': False,\n",
      " 'targets': [<tf.Tensor 'activation_6_target:0' shape=(?, ?) dtype=float32>],\n",
      " 'total_loss': <tf.Tensor 'mul_16:0' shape=() dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "pprint(vars(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSTM_UNITS = 256\n",
    "BATCH_SIZE = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "N_CLASSES = 10\n",
    "TRAINING_ITER = 1000\n",
    "\n",
    "def LSTM(x):\n",
    "    \n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=LSTM_UNITS)\n",
    "    \n",
    "    init_state = lstm_cell.zero_state(batch_size=BATCH_SIZE, dtype=tf.float32)\n",
    "    \n",
    "    outputs, final_state = tf.nn.dynamic_rnn(cell=lstm_cell,inputs=x,initial_state=init_state,time_major=False) \n",
    "    \n",
    "    return tf.unstack(tf.transpose(outputs, [1, 0, 2]))\n",
    "\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def init_biases(shape):\n",
    "    return tf.Variable(tf.zeros(shape) + 0.1)\n",
    "\n",
    "def add_layer(x, weights, biases, activation_function=None):\n",
    "    results = tf.matmul(x, weights) + biases\n",
    "    if activation_function:\n",
    "        return activation_function(results)\n",
    "    else:\n",
    "        return results\n",
    "\n",
    "weights = {'output': init_weights([LSTM_UNITS, N_CLASSES])}\n",
    "biases = {'output': init_biases([N_CLASSES])}\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, N_CLASSES])\n",
    "\n",
    "x_2d = tf.reshape(x, [-1, 28, 28])\n",
    "\n",
    "lstm_outputs = LSTM(x_2d)\n",
    "\n",
    "predictions = add_layer(lstm_outputs[-1], weights['output'], biases['output'], None)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=predictions))\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.arg_max(y, 1), tf.arg_max(predictions, 1)), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_ACC@0: 0.29\n",
      "TRAIN_ACC@50: 0.68\n",
      "TRAIN_ACC@100: 0.88\n",
      "TRAIN_ACC@150: 0.84\n",
      "TRAIN_ACC@200: 0.95\n",
      "TRAIN_ACC@250: 0.95\n",
      "TRAIN_ACC@300: 0.95\n",
      "TRAIN_ACC@350: 0.9\n",
      "TRAIN_ACC@400: 0.97\n",
      "TRAIN_ACC@450: 0.97\n",
      "TRAIN_ACC@500: 0.93\n",
      "TRAIN_ACC@550: 0.97\n",
      "TRAIN_ACC@600: 0.97\n",
      "TRAIN_ACC@650: 0.9\n",
      "TRAIN_ACC@700: 0.98\n",
      "TRAIN_ACC@750: 0.97\n",
      "TRAIN_ACC@800: 0.97\n",
      "TRAIN_ACC@850: 0.99\n",
      "TRAIN_ACC@900: 0.97\n",
      "TRAIN_ACC@950: 0.99\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(TRAINING_ITER):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
    "        sess.run(train_step, feed_dict= {x: batch_xs, y: batch_ys})\n",
    "        if i % 50 == 0:\n",
    "            print 'TRAIN_ACC@%d:' %i, sess.run(accuracy, feed_dict = {x: batch_xs, y:batch_ys})\n",
    "            \n",
    "            \n",
    "            #print 'VALID_ACC@%d:' %i, sess.run(accuracy, feed_dict = {x: mnist.validation.images, y: mnist.validation.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
